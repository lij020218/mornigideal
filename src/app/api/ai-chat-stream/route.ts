import { auth } from "@/auth";
import OpenAI from "openai";
import { logOpenAIUsage } from "@/lib/openai-usage";
import { routeChatRequest } from "@/lib/smart-chat-router";

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: Request) {
    try {
        const session = await auth();
        if (!session?.user?.email) {
            return new Response(JSON.stringify({ error: "Unauthorized" }), {
                status: 401,
                headers: { 'Content-Type': 'application/json' }
            });
        }

        const { messages, context } = await request.json();

        if (!messages || !Array.isArray(messages)) {
            return new Response(JSON.stringify({ error: "Messages are required" }), {
                status: 400,
                headers: { 'Content-Type': 'application/json' }
            });
        }

        // Get the latest user message
        const latestMessage = messages[messages.length - 1];
        if (latestMessage.role !== 'user') {
            return new Response(JSON.stringify({ error: "Last message must be from user" }), {
                status: 400,
                headers: { 'Content-Type': 'application/json' }
            });
        }

        // Try rule-based routing first
        const routeResult = routeChatRequest(latestMessage.content, context);

        if (routeResult.type === 'rule-based') {
            console.log('[AI Chat Stream] âœ… Handled by rule-based system - NO AI COST');

            const response: any = {
                message: routeResult.message || "ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.",
                actions: [],
            };

            // Add actions based on route result
            if (routeResult.action === 'add_schedule' && routeResult.data) {
                response.actions.push({
                    type: 'add_schedule',
                    label: '',
                    data: routeResult.data,
                });
            } else if (routeResult.action === 'show_briefings' && routeResult.data?.briefings) {
                // Add briefing actions
                routeResult.data.briefings.slice(0, 3).forEach((b: any) => {
                    response.actions.push({
                        type: 'open_briefing',
                        label: `${b.title} ìžì„¸ížˆ ë³´ê¸°`,
                        data: {
                            briefingId: b.id,
                            title: b.title,
                        },
                    });
                });
            }

            // Return as non-streaming for rule-based responses
            return new Response(JSON.stringify(response), {
                headers: { 'Content-Type': 'application/json' }
            });
        }

        // If AI is required, proceed with OpenAI streaming API call
        console.log('[AI Chat Stream] ðŸ¤– Complex request - using AI with streaming');

        // Get user profile for context
        let userContext = "";
        let scheduleContext = "";
        try {
            const { getUserByEmail } = await import("@/lib/users");
            const user = await getUserByEmail(session.user.email);
            if (user?.profile) {
                const p = user.profile;
                userContext = `
ì‚¬ìš©ìž ì •ë³´:
- ì´ë¦„: ${user.name}
- ì§ì—…: ${p.job || "ë¯¸ì„¤ì •"}
- ëª©í‘œ: ${p.goal || "ë¯¸ì„¤ì •"}
- ë ˆë²¨: ${p.level || "intermediate"}
- ê´€ì‹¬ ë¶„ì•¼: ${(p.interests || []).join(", ") || "ë¯¸ì„¤ì •"}
`;
                // Use schedules from context if provided
                if (context?.schedules && context.schedules.length > 0) {
                    scheduleContext = `\nì˜¤ëŠ˜ì˜ ì¼ì • (${context.currentDate}):\n${context.schedules.map((g: any) => `- ${g.startTime}: ${g.text}${g.completed ? ' âœ“ ì™„ë£Œ' : g.skipped ? ' âŠ˜ ê±´ë„ˆëœ€' : ''}`).join('\n')}\n`;
                }
            }
        } catch (e) {
            console.error("[AI Chat Stream] Failed to get user context:", e);
        }

        // Trend briefing context
        let trendContext = "";
        if (context?.trendBriefings && Array.isArray(context.trendBriefings)) {
            const briefings = context.trendBriefings;
            if (briefings.length > 0) {
                trendContext = `\nðŸ“° ì˜¤ëŠ˜ì˜ íŠ¸ë Œë“œ ë¸Œë¦¬í•‘ ì •ë³´:\n- ì´ ë¸Œë¦¬í•‘ ìˆ˜: ${briefings.length}ê°œ\n\në¸Œë¦¬í•‘ ëª©ë¡:\n${briefings.map((t: any, i: number) => `${i + 1}. [${t.category || 'ì¼ë°˜'}] ${t.title || t.name || 'ì œëª© ì—†ìŒ'}`).join('\n')}\n`;
            }
        }

        // Get current date/time for context
        const now = new Date();
        let currentDateContext = "";

        if (context?.currentDate && context?.currentTime) {
            const [year, month, day] = context.currentDate.split('-');
            const dateObj = new Date(parseInt(year), parseInt(month) - 1, parseInt(day));
            const weekdayNames = ['ì¼ìš”ì¼', 'ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼'];
            const weekday = weekdayNames[dateObj.getDay()];
            currentDateContext = `\ní˜„ìž¬ ë‚ ì§œ: ${year}ë…„ ${month}ì›” ${day}ì¼ ${weekday}\ní˜„ìž¬ ì‹œê°„: ${context.currentTime}\ní˜„ìž¬ ì—°ë„: ${year}ë…„\n\nì¤‘ìš”: ì‚¬ìš©ìžê°€ "ì˜¤ëŠ˜" ë˜ëŠ” "today"ë¼ê³  í•˜ë©´ ${year}ë…„ ${month}ì›” ${day}ì¼ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n`;
        } else {
            currentDateContext = `\ní˜„ìž¬ ë‚ ì§œ ë° ì‹œê°„: ${now.toLocaleString('ko-KR', { timeZone: 'Asia/Seoul', year: 'numeric', month: 'long', day: 'numeric', weekday: 'long', hour: '2-digit', minute: '2-digit' })}\ní˜„ìž¬ ì—°ë„: ${now.getFullYear()}ë…„\n`;
        }

        const systemPrompt = `ë‹¹ì‹ ì€ Fi.eri ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. ${currentDateContext}${userContext}${scheduleContext}${trendContext}

**í•µì‹¬ ê·œì¹™:**
1. ì¡´ëŒ“ë§ ì‚¬ìš© (í•„ìˆ˜), ë°˜ë§ ê¸ˆì§€.
2. ì§§ê³  í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€ (2-3ë¬¸ìž¥).
3. ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ìž‘ì„±. ë¶ˆë¦¿ í¬ì¸íŠ¸(-)ëŠ” ê¼­ í•„ìš”í•  ë•Œë§Œ ì‚¬ìš© (3ê°œ ì´ìƒ ë‚˜ì—´í•  ë•Œë§Œ).
4. ì¼ì • ì¶”ê°€/íŠ¸ë Œë“œ ìš”ì•½ ì™¸ì—ëŠ” actions ì—†ì´ messageë§Œ ì‘ë‹µ.

**ê¸°ëŠ¥ë³„ ì§€ì¹¨:**
- **ì¼ì • ì¶”ê°€**:
  - **ì¦‰ì‹œ ë“±ë¡ ì¡°ê±´** (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹í•˜ë©´ ë°”ë¡œ add_schedule action í¬í•¨):
    1. ì‚¬ìš©ìžê°€ "ë°”ë¡œ ë“±ë¡", "í•„ìš” ì—†ì–´", "ì—†ì–´", "ê·¸ëƒ¥ ë“±ë¡", "ì„¸ë¶€ì‚¬í•­ í•„ìš” ì—†ì–´", "ê¸°ë¡í•  í•„ìš” ì—†ì–´" ë“± ëª…í™•í•œ ì˜ì‚¬ í‘œí˜„
    2. ì‚¬ìš©ìžê°€ ì´ë¯¸ ìž¥ì†Œ/ë©”ëª¨ë¥¼ ì œê³µí•¨
    3. ì´ì „ ëŒ€í™”ì—ì„œ ì´ë¯¸ ì„¸ë¶€ì‚¬í•­ ì§ˆë¬¸ì„ í–ˆê³  ì‚¬ìš©ìžê°€ ë‹µë³€í•¨
  - **ë¬¼ì–´ë³´ê¸° ì¡°ê±´**: ìœ„ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•Šê³ , ì‚¬ìš©ìžê°€ ì²˜ìŒìœ¼ë¡œ ì¼ì •ë§Œ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ "ìž¥ì†Œë‚˜ ì„¸ë¶€ ì‚¬í•­ë„ ê°™ì´ ê¸°ë¡í• ê¹Œìš”?"ë¼ê³  **ë”± í•œ ë²ˆë§Œ** ë¬¼ì–´ë´„.
  - ìž¥ì†Œ(location), ë©”ëª¨(memo) ì •ë³´ê°€ ìžˆìœ¼ë©´ dataì— í¬í•¨, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìžì—´ë¡œ.
- **íŠ¸ë Œë“œ ë¸Œë¦¬í•‘**: ì»¨í…ìŠ¤íŠ¸ ì°¸ê³ í•˜ì—¬ ìš”ì•½í•˜ê³  actionsì— open_briefing í¬í•¨.

**JSON ì‘ë‹µ í˜•ì‹ (ì—„ìˆ˜):**
{
  "message": "ì‚¬ìš©ìžì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ (ì¡´ëŒ“ë§)",
  "actions": [
    {
      "type": "add_schedule" | "open_briefing",
      "label": "ë²„íŠ¼ í…ìŠ¤íŠ¸",
      "data": {
        // add_schedule: { text, startTime, endTime, specificDate, color: 'primary' }
        // open_briefing: { briefingId, title }
      }
    }
  ]
}`;

        const modelName = "gpt-5-mini-2025-08-07";

        // Create streaming response
        const stream = await openai.chat.completions.create({
            model: modelName,
            messages: [
                { role: "system", content: systemPrompt },
                ...messages.slice(-10),
            ],
            temperature: 1.0,
            max_completion_tokens: 4096,
            response_format: { type: "json_object" },
            stream: true,
        });

        // Create a ReadableStream for SSE
        const encoder = new TextEncoder();
        let fullResponse = "";
        let inputTokens = 0;
        let outputTokens = 0;

        const readableStream = new ReadableStream({
            async start(controller) {
                try {
                    for await (const chunk of stream) {
                        const content = chunk.choices[0]?.delta?.content || "";
                        if (content) {
                            fullResponse += content;
                            // Send SSE event
                            controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content })}\n\n`));
                        }

                        // Track token usage (only available in the final chunk)
                        if (chunk.usage) {
                            inputTokens = chunk.usage.prompt_tokens;
                            outputTokens = chunk.usage.completion_tokens;
                        }
                    }

                    // Log usage after stream completes
                    if (inputTokens > 0 || outputTokens > 0) {
                        await logOpenAIUsage(
                            session.user.email!,
                            modelName,
                            '/api/ai-chat-stream',
                            inputTokens,
                            outputTokens
                        );
                    }

                    // Send done event
                    controller.enqueue(encoder.encode(`data: ${JSON.stringify({ done: true })}\n\n`));
                    controller.close();
                } catch (error) {
                    console.error("[AI Chat Stream] Streaming error:", error);
                    controller.error(error);
                }
            }
        });

        return new Response(readableStream, {
            headers: {
                'Content-Type': 'text/event-stream',
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
            },
        });

    } catch (error: any) {
        console.error("[AI Chat Stream] Error:", error);
        return new Response(JSON.stringify({ error: "Failed to generate response" }), {
            status: 500,
            headers: { 'Content-Type': 'application/json' }
        });
    }
}
