import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";
import { getTrendsCache, saveDetailCache, generateTrendId, saveTrendsCache } from "@/lib/newsCache";

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY || process.env.GEMINI_API_KEY || "");

// TOP PRIORITY SOURCES (Tier 1 - Search these FIRST)
const TOP_PRIORITY_SOURCES = [
    { name: "BBC Business", urlPattern: "bbc.com/business", category: "ê¸€ë¡œë²Œ ë¹„ì¦ˆë‹ˆìŠ¤" },
    { name: "BBC Korean", urlPattern: "bbc.com/korean", category: "í•œêµ­ì–´ ë‰´ìŠ¤" },
    { name: "Reuters", urlPattern: "reuters.com", category: "ì†ë³´Â·êµ­ì œ" },
    { name: "AP News", urlPattern: "apnews.com", category: "ì†ë³´" },
    { name: "CNN", urlPattern: "cnn.com", category: "êµ­ì œÂ·ë¹„ì¦ˆë‹ˆìŠ¤" },
    { name: "TechCrunch", urlPattern: "techcrunch.com", category: "í…Œí¬Â·ìŠ¤íƒ€íŠ¸ì—…" }
];

// PREMIUM SOURCES (Tier 2 - Search if Tier 1 doesn't have enough)
const PREMIUM_SOURCES = [
    // Economic & Business
    { name: "Bloomberg", urlPattern: "bloomberg.com", category: "ê²½ì œÂ·ë¹„ì¦ˆë‹ˆìŠ¤" },
    { name: "Financial Times", urlPattern: "ft.com", category: "ê²½ì œÂ·ê¸ˆìœµ" },
    { name: "The Wall Street Journal", urlPattern: "wsj.com", category: "ë¹„ì¦ˆë‹ˆìŠ¤" },
    { name: "The Economist", urlPattern: "economist.com", category: "ê²½ì œÂ·ì •ì±…" },

    // Global News
    { name: "BBC", urlPattern: "bbc.com", category: "êµ­ì œ" },

    // US Major
    { name: "The New York Times", urlPattern: "nytimes.com", category: "ì¢…í•©" },
    { name: "The Washington Post", urlPattern: "washingtonpost.com", category: "ì •ì¹˜Â·ì‚¬íšŒ" },

    // Asia
    { name: "Nikkei Asia", urlPattern: "asia.nikkei.com", category: "ì•„ì‹œì•„ ê²½ì œ" },
    { name: "South China Morning Post", urlPattern: "scmp.com", category: "ì•„ì‹œì•„Â·ì¤‘êµ­" },

    // Tech & Startup
    { name: "Wired", urlPattern: "wired.com", category: "ê¸°ìˆ Â·ë¬¸í™”" },
    { name: "The Information", urlPattern: "theinformation.com", category: "í…Œí¬Â·ì¸ì‚¬ì´íŠ¸" }
];

// JSON parser
function cleanAndParseJSON(text: string): any {
    let cleanText = text.replace(/```json/g, "").replace(/```/g, "").trim();

    const firstBrace = cleanText.indexOf('{');
    const firstBracket = cleanText.indexOf('[');

    let start = -1;
    let openChar = '';
    let closeChar = '';

    if (firstBrace !== -1 && (firstBracket === -1 || firstBrace < firstBracket)) {
        start = firstBrace;
        openChar = '{';
        closeChar = '}';
    } else if (firstBracket !== -1) {
        start = firstBracket;
        openChar = '[';
        closeChar = ']';
    }

    if (start !== -1) {
        let balance = 0;
        let inString = false;
        let escapeNext = false;

        for (let i = start; i < cleanText.length; i++) {
            const char = cleanText[i];

            if (escapeNext) {
                escapeNext = false;
                continue;
            }
            if (char === '\\') {
                escapeNext = true;
                continue;
            }
            if (char === '"') {
                inString = !inString;
                continue;
            }

            if (!inString) {
                if (char === openChar) {
                    balance++;
                } else if (char === closeChar) {
                    balance--;
                    if (balance === 0) {
                        const jsonCandidate = cleanText.substring(start, i + 1);
                        return JSON.parse(jsonCandidate);
                    }
                }
            }
        }
    }

    return JSON.parse(cleanText);
}

export async function GET(request: Request) {
    try {
        const { searchParams } = new URL(request.url);
        const job = searchParams.get("job") || "Marketer";
        const goal = searchParams.get("goal");
        const interests = searchParams.get("interests");
        const forceRefresh = searchParams.get("forceRefresh") === "true";

        // Check cache first - only return if it's from today and not force refreshing
        const cachedData = await getTrendsCache();
        const today = new Date().toISOString().split('T')[0];

        if (!forceRefresh && cachedData && cachedData.trends.length > 0) {
            const cacheDate = new Date(cachedData.lastUpdated).toISOString().split('T')[0];
            if (cacheDate === today) {
                console.log('[API] Returning cached trends from today:', cachedData.lastUpdated);
                return NextResponse.json({
                    trends: cachedData.trends,
                    cached: true,
                    lastUpdated: cachedData.lastUpdated
                });
            }
        }

        if (forceRefresh) {
            console.log('[API] Force refresh requested with interests:', interests);
        }

        console.log('[API] Generating new daily briefing with Google Search...');

        // Use configured Gemini model with Google Search tool
        const modelName = process.env.GEMINI_MODEL || "gemini-2.0-flash-exp";
        console.log(`[API] Using model: ${modelName}`);

        const model = genAI.getGenerativeModel({
            model: modelName,
            // @ts-expect-error - googleSearch is valid in latest SDK
            tools: [{ googleSearch: {} }]
        });

        const sevenDaysAgo = new Date();
        sevenDaysAgo.setDate(sevenDaysAgo.getDate() - 7);
        const dateStr = sevenDaysAgo.toISOString().split('T')[0];

        // Tier 1: Top Priority Sources
        const topPrioritySources = TOP_PRIORITY_SOURCES.map(s => s.name);
        const topPrioritySites = TOP_PRIORITY_SOURCES.map(s => `site:${s.urlPattern}`);

        // Tier 2: Premium Sources (excluding duplicates from Tier 1)
        const tier1Patterns = TOP_PRIORITY_SOURCES.map(s => s.urlPattern.toLowerCase());
        const premiumOnlySources = PREMIUM_SOURCES
            .filter(s => !tier1Patterns.some(pattern => s.urlPattern.toLowerCase().includes(pattern)))
            .map(s => s.name);

        const jobEnglish = job === "ë§ˆì¼€í„°" ? "marketing" : job === "ê°œë°œì" ? "developer" : "business professional";
        const jobKorean = job;

        const prompt = `
**TODAY'S DATE:** ${today}
**TARGET:** ${job} professionals
${goal ? `**GOAL:** ${goal}` : ""}
${interests ? `**INTERESTS:** ${interests}` : ""}

**ğŸ¯ MISSION:**
Find 6 recent news articles (published after ${dateStr}) using a 3-TIER priority system with BILINGUAL search (English + Korean).

**ğŸ“Š 3-TIER PRIORITY SYSTEM:**

**ğŸ¥‡ TIER 1 - TOP PRIORITY (Search FIRST):**
${topPrioritySources.map(s => `â€¢ ${s}`).join('\n')}

**ğŸ¥ˆ TIER 2 - PREMIUM SOURCES (Search if Tier 1 insufficient):**
${premiumOnlySources.map(s => `â€¢ ${s}`).join('\n')}

**ğŸ¥‰ TIER 3 - GENERAL (Last resort only):**
â€¢ Other reputable news sources

**ğŸ” BILINGUAL SEARCH STRATEGY:**

**TIER 1 - Use SITE FILTERS with interests (English + Korean):**

English searches:
- site:reuters.com (AI OR technology OR ${jobEnglish}) after:${dateStr}
- site:apnews.com (AI OR innovation OR ${jobEnglish}) after:${dateStr}
- site:bbc.com/business (AI OR business OR ${jobEnglish}) after:${dateStr}
- site:cnn.com (technology OR business OR ${jobEnglish}) after:${dateStr}
- site:techcrunch.com (AI OR startup OR ${jobEnglish}) after:${dateStr}
${interests ? `
Interest-specific (English):
${interests.split(',').map(i => `- site:reuters.com "${i.trim()}" after:${dateStr}
- site:apnews.com "${i.trim()}" after:${dateStr}
- site:techcrunch.com "${i.trim()}" after:${dateStr}`).join('\n')}
` : ""}

Korean searches:
- site:bbc.com/korean (ì¸ê³µì§€ëŠ¥ OR ë¹„ì¦ˆë‹ˆìŠ¤ OR ${jobKorean}) after:${dateStr}
- site:reuters.com (í•œêµ­ OR ê¸°ìˆ  OR ${jobKorean}) after:${dateStr}
- site:cnn.com (ì¸ê³µì§€ëŠ¥ OR ê¸°ìˆ  OR ${jobKorean}) after:${dateStr}
${interests ? `
Interest-specific (Korean):
${interests.split(',').map(i => `- site:reuters.com "${i.trim()}" after:${dateStr}
- site:bbc.com/korean "${i.trim()}" after:${dateStr}`).join('\n')}
` : ""}

**TIER 2 - Use SOURCE NAMES with interests (English + Korean):**

English searches:
- "Bloomberg" (AI OR ${jobEnglish} OR technology) after:${dateStr}
- "Financial Times" (business OR AI OR ${jobEnglish}) after:${dateStr}
- "Wall Street Journal" (technology OR ${jobEnglish}) after:${dateStr}
- "New York Times" (AI OR business OR ${jobEnglish}) after:${dateStr}
- "Wired" (AI OR technology) after:${dateStr}
${interests ? `
Interest-specific (English):
${interests.split(',').map(i => `- "Bloomberg" "${i.trim()}" after:${dateStr}
- "Financial Times" "${i.trim()}" after:${dateStr}
- "Wired" "${i.trim()}" after:${dateStr}`).join('\n')}
` : ""}

Korean searches:
- "ë¸”ë£¸ë²„ê·¸" (ì¸ê³µì§€ëŠ¥ OR ${jobKorean}) after:${dateStr}
- "íŒŒì´ë‚¸ì…œíƒ€ì„ìŠ¤" (ê¸°ìˆ  OR ${jobKorean}) after:${dateStr}
- "ë‰´ìš•íƒ€ì„ìŠ¤" (ë¹„ì¦ˆë‹ˆìŠ¤ OR ${jobKorean}) after:${dateStr}
${interests ? `
Interest-specific (Korean):
${interests.split(',').map(i => `- "Bloomberg" "${i.trim()}" after:${dateStr}
- "ë‰´ìš•íƒ€ì„ìŠ¤" "${i.trim()}" after:${dateStr}`).join('\n')}
` : ""}

**TIER 3 - GENERAL search (English + Korean):**

English searches:
- "${jobEnglish} AI news" after:${dateStr}
- "latest ${jobEnglish} technology trends" after:${dateStr}
${interests ? `- ${interests.split(',').map(i => `"${i.trim()} news"`).join(' OR ')} after:${dateStr}` : ""}

Korean searches:
- "${jobKorean} ì¸ê³µì§€ëŠ¥ ë‰´ìŠ¤" after:${dateStr}
- "${jobKorean} ê¸°ìˆ  íŠ¸ë Œë“œ" after:${dateStr}
${interests ? `- ${interests.split(',').map(i => `"${i.trim()} ë‰´ìŠ¤"`).join(' OR ')} after:${dateStr}` : ""}

**ğŸ“‹ EXECUTION STEPS:**

1. **Execute Tier 1 searches** (both English AND Korean):
   - Use site: filters with keywords
   - Search each interest separately
   - Collect 8-12 candidates

2. **If less than 6 articles, execute Tier 2** (both English AND Korean):
   - Use source names in quotes
   - Search with interests
   - Collect additional candidates

3. **If still less than 6, execute Tier 3** (both English AND Korean):
   - General web search
   - Focus on interests and job

4. **Select BEST 6 articles** ensuring:
   âœ“ Maximum from Tier 1
   âœ“ Fill gaps with Tier 2
   âœ“ Use Tier 3 only if necessary
   âœ“ Published ${dateStr} or later
   âœ“ Diverse topics
   âœ“ Mix of English AND Korean results if available
   ${interests ? `âœ“ At least 2-3 related to: ${interests}` : ""}

**ğŸ“Š OUTPUT (JSON):**
{
  "briefings": [
    {
      "title": "Korean translation of article title",
      "category": "AI | Business | Tech | Finance | Strategy | Innovation",
      "summary": "Korean 2-3 sentence summary - WHY ${job} should care",
      "sourceName": "Exact source name (e.g., 'BBC Business', 'Reuters', 'Bloomberg')",
      "sourceUrl": "Complete HTTPS URL from search",
      "publishedDate": "YYYY-MM-DD",
      "relevance": "Korean 1-sentence: specific value for ${job}"
    }
  ]
}

**âš ï¸ CRITICAL RULES:**
âœ“ Search BOTH English AND Korean for each tier
âœ“ Tier 1: Use site:domain.com filters
âœ“ Tier 2: Use "Source Name" in quotes
âœ“ Tier 3: General search
âœ“ REAL URLs only from Google Search
âœ“ Published ${dateStr} or later
âœ“ Full HTTPS URLs required
âœ“ Prioritize Tier 1 > Tier 2 > Tier 3

**START NOW** - Execute bilingual searches starting with Tier 1 site filters.`;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();

        console.log('[API] Gemini response received. Length:', text.length);

        // Log grounding metadata to verify search was used
        if (response.candidates && response.candidates[0].groundingMetadata) {
            console.log('[API] âœ… Google Search was used! Grounding metadata present.');
        } else {
            console.warn('[API] âš ï¸ No grounding metadata - search might not have been performed.');
        }

        let data;
        try {
            data = cleanAndParseJSON(text);
        } catch (parseError) {
            console.error("[API] Failed to parse JSON", parseError);
            console.error("[API] Failed text:", text);
            return NextResponse.json({ error: "Failed to parse briefings" }, { status: 500 });
        }

        const briefings = data.briefings || [];

        // Prefer premium sources; if not enough, backfill with others
        const premiumPatterns = PREMIUM_SOURCES.map(s => s.urlPattern.replace(/^https?:\/\//, "").replace(/^www\./, ""));
        const isPremiumSource = (item: any) => {
            const url = item?.sourceUrl || "";
            const normalized = url.startsWith("http") ? url : `https://${url.replace(/^\/\//, "")}`;
            try {
                const host = new URL(normalized).hostname.replace(/^www\./, "");
                return premiumPatterns.some(pattern => host === pattern || host.endsWith(`.${pattern}`) || host.includes(pattern));
            } catch {
                const sourceName = (item?.sourceName || "").toLowerCase();
                return premiumPatterns.some(pattern => sourceName.includes(pattern.split(".")[0]));
            }
        };

        const premiumBriefings = (briefings || []).filter(isPremiumSource);
        const nonPremiumBriefings = (briefings || []).filter((item: any) => !isPremiumSource(item));

        // Aim for at least 4 premium items; fill remaining slots with others if needed
        const desiredCount = Math.min(briefings.length, 6);
        const finalBriefings = [...premiumBriefings, ...nonPremiumBriefings].slice(0, desiredCount);

        if (!Array.isArray(finalBriefings) || finalBriefings.length === 0) {
            return NextResponse.json({ error: "Invalid response format" }, { status: 500 });
        }

        console.log(`[API] Parsed ${briefings.length} briefings (premium ${premiumBriefings.length}, final ${finalBriefings.length})`);

        const trends = finalBriefings.map((item: any) => ({
            id: generateTrendId(item.title),
            title: item.title,
            category: item.category || "General",
            summary: item.summary,
            time: item.publishedDate || today,
            imageColor: "bg-blue-500/20",
            originalUrl: item.sourceUrl,
            imageUrl: "",
            source: item.sourceName,
            relevance: item.relevance
        }));

        // Save to cache - this will be today's briefing
        await saveTrendsCache(trends, true); // Clear old trends

        return NextResponse.json({
            trends,
            cached: false,
            lastUpdated: new Date().toISOString()
        });

    } catch (error) {
        console.error("Error fetching trends:", error);
        return NextResponse.json({ error: "Failed to fetch trends" }, { status: 500 });
    }
}

export async function POST(request: Request) {
    try {
        const { title, level, job, originalUrl, summary, trendId } = await request.json();

        // Check cache first
        if (trendId) {
            const cachedDetail = await (async () => {
                const { getDetailCache } = await import("@/lib/newsCache");
                return getDetailCache(trendId);
            })();

            if (cachedDetail) {
                return NextResponse.json({ detail: cachedDetail, cached: true });
            }
        }

        const modelName = process.env.GEMINI_MODEL || "gemini-3-pro-preview";
        const model = genAI.getGenerativeModel({
            model: modelName,
            generationConfig: { responseMimeType: "application/json" }
        });

        const prompt = `
You are an expert mentor for ${level}-level ${job} professionals.

**CONTEXT:**
- Article Title: "${title}"
- Basic Summary: ${summary}
- Source: ${originalUrl}

**YOUR TASK:**
Create a comprehensive briefing that helps ${level} ${job} understand this news deeply.

**REQUIRED SECTIONS:**

1. **í•µì‹¬ ë‚´ìš© (Core Content)**
   - What happened? Key facts and context
   - Why is this significant?
   - What's the bigger picture?

2. **${level} ${job}ì¸ ë‹¹ì‹ ì—ê²Œ (For You as ${level} ${job})**
   - How does this directly impact ${job} professionals?
   - What opportunities or challenges does this present?
   - Industry-specific implications

3. **ì´ ë¸Œë¦¬í•‘ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ê²ƒ (Key Takeaways)**
   - 3-4 bullet points of critical insights
   - Actionable knowledge
   - Strategic implications

4. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ (Action Items)**
   - 3 specific actions ${level} ${job} can take
   - Both short-term and long-term suggestions
   - Practical and concrete

**OUTPUT FORMAT (JSON):**
{
  "title": "Engaging Korean title (clear and specific)",
  "content": "### í•µì‹¬ ë‚´ìš©\\n\\n[detailed content]\\n\\n### ${level} ${job}ì¸ ë‹¹ì‹ ì—ê²Œ\\n\\n[personalized analysis]\\n\\n### ì´ ë¸Œë¦¬í•‘ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ê²ƒ\\n\\n- **í¬ì¸íŠ¸ 1**\\n- **í¬ì¸íŠ¸ 2**\\n- **í¬ì¸íŠ¸ 3**",
  "keyTakeaways": ["Insight 1", "Insight 2", "Insight 3"],
  "actionItems": ["Action 1", "Action 2", "Action 3"],
  "originalUrl": "${originalUrl}"
}

Write in Korean. Be insightful, practical, and tailored to ${level} ${job}.`;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();

        let detail;
        try {
            detail = cleanAndParseJSON(text);
        } catch (e) {
            console.error("Failed to parse detail JSON", e);
            const simpleClean = text.replace(/```json/g, "").replace(/```/g, "").trim();
            detail = JSON.parse(simpleClean);
        }

        // Cache the detail
        if (trendId) {
            await saveDetailCache(trendId, detail);
        }

        return NextResponse.json({
            detail: { ...detail, originalUrl: originalUrl || "" },
            cached: false
        });
    } catch (error) {
        console.error("Error generating briefing detail:", error);
        return NextResponse.json({ error: "Failed to generate briefing detail" }, { status: 500 });
    }
}
